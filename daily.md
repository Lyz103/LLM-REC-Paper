# Daily papers' abstract
**ğŸ“…2024-04-02**  
**âœ…IISAN: Efficiently Adapting Multimodal Representation for Sequential Recommendation with Decoupled PEFT**  
Multimodal foundation models are transformative in sequential recommender systems, leveraging powerful representation learning capabilities. While Parameter-efficient Fine-tuning (PEFT) is commonly used to adapt foundation models for recommendation tasks, most research prioritizes parameter efficiency, often overlooking critical factors like GPU memory efficiency and training speed. Addressing this gap, our paper introduces IISAN (Intra- and Inter-modal Side Adapted Network for Multimodal Representation), a simple plug-and-play architecture using a Decoupled PEFT structure and exploiting both intra- and inter-modal adaptation.
IISAN matches the performance of full fine-tuning (FFT) and state-of-the-art PEFT. More importantly, it significantly reduces GPU memory usage - from 47GB to just 3GB for multimodal sequential recommendation tasks. Additionally, it accelerates training time per epoch from 443s to 22s compared to FFT. This is also a notable improvement over the Adapter and LoRA, which require 37-39 GB GPU memory and 350-380 seconds per epoch for training.
Furthermore, we propose a new composite efficiency metric, TPME (Training-time, Parameter, and GPU Memory Efficiency) to alleviate the prevalent misconception that "parameter efficiency represents overall efficiency". TPME provides more comprehensive insights into practical efficiency comparisons between different methods. Besides, we give an accessible efficiency analysis of all PEFT and FFT approaches, which demonstrate the superiority of IISAN. We release our codes and other materials at this https URL.  
æˆ‘ä»¬çš„è®ºæ–‡ä»‹ç»äº†IISANï¼ˆIntra- and Inter-modal Side Adapted Network for Multimodal Representationï¼‰ï¼Œè¿™æ˜¯ä¸€ç§ç®€å•çš„å³æ’å³ç”¨æ¶æ„ï¼Œä½¿ç”¨äº†åˆ†ç¦»çš„PEFTç»“æ„ï¼Œå¹¶åˆ©ç”¨äº†æ¨¡æ€å†…éƒ¨å’Œæ¨¡æ€é—´çš„é€‚åº”æ€§ï¼Œä»¥è§£å†³å¤šæ¨¡æ€åºåˆ—æ¨èä»»åŠ¡ä¸­GPUå†…å­˜æ•ˆç‡å’Œè®­ç»ƒé€Ÿåº¦çš„é—®é¢˜ã€‚IISANèƒ½å¤Ÿè¾¾åˆ°å…¨é‡å¾®è°ƒï¼ˆFFTï¼‰å’Œæœ€å…ˆè¿›PEFTçš„æ€§èƒ½æ°´å¹³ï¼Œå¹¶ä¸”æ˜¾è‘—å‡å°‘äº†GPUå†…å­˜ä½¿ç”¨é‡ï¼Œä»47GBé™ä½åˆ°äº†ä»…3GBã€‚æ­¤å¤–ï¼Œå®ƒè¿˜åŠ å¿«äº†æ¯ä¸ªepochçš„è®­ç»ƒæ—¶é—´ï¼Œä»443ç§’ç¼©çŸ­åˆ°äº†22ç§’ã€‚ä¸éœ€è¦37-39 GB GPUå†…å­˜å’Œ350-380ç§’æ¯ä¸ªepochè®­ç»ƒæ—¶é—´çš„Adapterå’ŒLoRAç›¸æ¯”ï¼Œè¿™ä¹Ÿæ˜¯ä¸€ä¸ªæ˜¾è‘—çš„æ”¹è¿›ã€‚

æˆ‘ä»¬è¿˜æå‡ºäº†ä¸€ä¸ªæ–°çš„å¤åˆæ•ˆç‡æŒ‡æ ‡TPMEï¼ˆTraining-time, Parameter, and GPU Memory Efficiencyï¼‰ï¼Œä»¥æ¶ˆé™¤â€œå‚æ•°æ•ˆç‡ä»£è¡¨æ€»ä½“æ•ˆç‡â€çš„æ™®éè¯¯è§£ã€‚TPMEæä¾›äº†å¯¹ä¸åŒæ–¹æ³•çš„æ›´å…¨é¢çš„å®é™…æ•ˆç‡æ¯”è¾ƒã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬å¯¹æ‰€æœ‰PEFTå’ŒFFTæ–¹æ³•è¿›è¡Œäº†å¯è®¿é—®çš„æ•ˆç‡åˆ†æï¼Œå±•ç¤ºäº†IISANçš„ä¼˜è¶Šæ€§ã€‚æˆ‘ä»¬åœ¨æ­¤https URLå‘å¸ƒäº†æˆ‘ä»¬çš„ä»£ç å’Œå…¶ä»–ææ–™ã€‚

**âœ…Where to Move Next: Zero-shot Generalization of LLMs for Next POI Recommendation**  
Next Point-of-interest (POI) recommendation provides valuable suggestions for users to explore their surrounding environment. Existing studies rely on building recommendation models from large-scale users' check-in data, which is task-specific and needs extensive computational resources. Recently, the pretrained large language models (LLMs) have achieved significant advancements in various NLP tasks and have also been investigated for recommendation scenarios. However, the generalization abilities of LLMs still are unexplored to address the next POI recommendations, where users' geographical movement patterns should be extracted. Although there are studies that leverage LLMs for next-item recommendations, they fail to consider the geographical influence and sequential transitions. Hence, they cannot effectively solve the next POI recommendation task. To this end, we design novel prompting strategies and conduct empirical studies to assess the capability of LLMs, e.g., ChatGPT, for predicting a user's next check-in. Specifically, we consider several essential factors in human movement behaviors, including user geographical preference, spatial distance, and sequential transitions, and formulate the recommendation task as a ranking problem. Through extensive experiments on two widely used real-world datasets, we derive several key findings. Empirical evaluations demonstrate that LLMs have promising zero-shot recommendation abilities and can provide accurate and reasonable predictions. We also reveal that LLMs cannot accurately comprehend geographical context information and are sensitive to the order of presentation of candidate POIs, which shows the limitations of LLMs and necessitates further research on robust human mobility reasoning mechanisms.  
ä¸‹ä¸€ä¸ªæ„Ÿå…´è¶£ç‚¹ï¼ˆPOIï¼‰æ¨èä¸ºç”¨æˆ·æä¾›äº†æœ‰ä»·å€¼çš„å»ºè®®ï¼Œå¸®åŠ©ä»–ä»¬æ¢ç´¢å‘¨å›´ç¯å¢ƒã€‚ç°æœ‰ç ”ç©¶ä¾èµ–äºä»å¤§è§„æ¨¡ç”¨æˆ·ç­¾åˆ°æ•°æ®æ„å»ºæ¨èæ¨¡å‹ï¼Œè¿™æ˜¯ä¸€é¡¹ç‰¹å®šä»»åŠ¡ï¼Œå¹¶éœ€è¦å¤§é‡è®¡ç®—èµ„æºã€‚æœ€è¿‘ï¼Œé¢„è®­ç»ƒçš„å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨å„ç§è‡ªç„¶è¯­è¨€å¤„ç†ä»»åŠ¡ä¸­å–å¾—äº†é‡å¤§è¿›å±•ï¼Œå¹¶ä¸”ä¹Ÿå·²ç»åœ¨æ¨èåœºæ™¯ä¸­è¿›è¡Œäº†ç ”ç©¶ã€‚ç„¶è€Œï¼ŒLLMsçš„æ³›åŒ–èƒ½åŠ›åœ¨è§£å†³ä¸‹ä¸€ä¸ªPOIæ¨èä»»åŠ¡æ—¶ä»æœªè¢«æ¢ç´¢ï¼Œå…¶ä¸­éœ€è¦æå–ç”¨æˆ·çš„åœ°ç†ç§»åŠ¨æ¨¡å¼ã€‚è™½ç„¶æœ‰ç ”ç©¶åˆ©ç”¨LLMsè¿›è¡Œä¸‹ä¸€ä¸ªé¡¹ç›®çš„æ¨èï¼Œä½†å®ƒä»¬æœªèƒ½è€ƒè™‘åœ°ç†å½±å“å’Œåºåˆ—è½¬æ¢ã€‚å› æ­¤ï¼Œå®ƒä»¬æ— æ³•æœ‰æ•ˆè§£å†³ä¸‹ä¸€ä¸ªPOIæ¨èä»»åŠ¡ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬è®¾è®¡äº†æ–°é¢–çš„æç¤ºç­–ç•¥ï¼Œå¹¶è¿›è¡Œäº†å®è¯ç ”ç©¶ï¼Œä»¥è¯„ä¼°LLMsï¼ˆå¦‚ChatGPTï¼‰é¢„æµ‹ç”¨æˆ·ä¸‹ä¸€ä¸ªç­¾åˆ°çš„èƒ½åŠ›ã€‚å…·ä½“è€Œè¨€ï¼Œæˆ‘ä»¬è€ƒè™‘äº†äººç±»ç§»åŠ¨è¡Œä¸ºä¸­çš„å‡ ä¸ªé‡è¦å› ç´ ï¼ŒåŒ…æ‹¬ç”¨æˆ·çš„åœ°ç†åå¥½ã€ç©ºé—´è·ç¦»å’Œåºåˆ—è½¬æ¢ï¼Œå¹¶å°†æ¨èä»»åŠ¡å½¢å¼åŒ–ä¸ºæ’åé—®é¢˜ã€‚é€šè¿‡å¯¹ä¸¤ä¸ªå¹¿æ³›ä½¿ç”¨çš„çœŸå®ä¸–ç•Œæ•°æ®é›†è¿›è¡Œå¤§é‡å®éªŒï¼Œæˆ‘ä»¬å¾—å‡ºäº†å‡ ä¸ªå…³é”®å‘ç°ã€‚å®è¯è¯„ä¼°è¡¨æ˜ï¼ŒLLMså…·æœ‰æœ‰å‰é€”çš„é›¶-shotæ¨èèƒ½åŠ›ï¼Œå¹¶ä¸”å¯ä»¥æä¾›å‡†ç¡®åˆç†çš„é¢„æµ‹ã€‚æˆ‘ä»¬è¿˜æ­ç¤ºäº†LLMsæ— æ³•å‡†ç¡®ç†è§£åœ°ç†èƒŒæ™¯ä¿¡æ¯ï¼Œå¹¶ä¸”å¯¹å€™é€‰POIçš„å‘ˆç°é¡ºåºæ•æ„Ÿï¼Œè¿™æ˜¾ç¤ºäº†LLMsçš„å±€é™æ€§ï¼Œéœ€è¦è¿›ä¸€æ­¥ç ”ç©¶ç¨³å¥çš„äººç±»ç§»åŠ¨æ¨ç†æœºåˆ¶ã€‚  
  

**ğŸ“…2024-04-01** 
**âœ…EEG-SVRec: An EEG Dataset with User Multidimensional Affective Engagement Labels in Short Video Recommendation**  
In recent years, short video platforms have gained widespread popularity, making the quality of video recommendations crucial for retaining users. Existing recommendation systems primarily rely on behavioral data, which faces limitations when inferring user preferences due to issues such as data sparsity and noise from accidental interactions or personal habits. To address these challenges and provide a more comprehensive understanding of user affective experience and cognitive activity, we propose EEG-SVRec, the first EEG dataset with User Multidimensional Affective Engagement Labels in Short Video Recommendation. The study involves 30 participants and collects 3,657 interactions, offering a rich dataset that can be used for a deeper exploration of user preference and cognitive activity. By incorporating selfassessment techniques and real-time, low-cost EEG signals, we offer a more detailed understanding user affective experiences (valence, arousal, immersion, interest, visual and auditory) and the cognitive mechanisms behind their behavior. We establish benchmarks for rating prediction by the recommendation algorithm, showing significant improvement with the inclusion of EEG signals. Furthermore, we demonstrate the potential of this dataset in gaining insights into the affective experience and cognitive activity behind user behaviors in recommender systems. This work presents a novel perspective for enhancing short video recommendation by leveraging the rich information contained in EEG signals and multidimensional affective engagement scores, paving the way for future research in short video recommendation systems.  
è¿‘å¹´æ¥ï¼ŒçŸ­è§†é¢‘å¹³å°å¹¿å—æ¬¢è¿ï¼Œå› æ­¤è§†é¢‘æ¨èè´¨é‡å¯¹äºç•™ä½ç”¨æˆ·è‡³å…³é‡è¦ã€‚ç°æœ‰çš„æ¨èç³»ç»Ÿä¸»è¦ä¾èµ–äºè¡Œä¸ºæ•°æ®ï¼Œä½†ç”±äºæ•°æ®ç¨€ç–æ€§ä»¥åŠæ„å¤–äº¤äº’æˆ–ä¸ªäººä¹ æƒ¯ç­‰é—®é¢˜å¯¼è‡´çš„å™ªéŸ³ï¼Œæ¨æ–­ç”¨æˆ·åå¥½æ—¶é¢ä¸´ä¸€å®šçš„é™åˆ¶ã€‚ä¸ºäº†è§£å†³è¿™äº›æŒ‘æˆ˜å¹¶æä¾›å¯¹ç”¨æˆ·æƒ…æ„Ÿä½“éªŒå’Œè®¤çŸ¥æ´»åŠ¨æ›´å…¨é¢çš„ç†è§£ï¼Œæˆ‘ä»¬æå‡ºäº†EEG-SVRecï¼Œè¿™æ˜¯é¦–ä¸ªå…·æœ‰çŸ­è§†é¢‘æ¨èä¸­ç”¨æˆ·å¤šç»´æƒ…æ„Ÿå‚ä¸æ ‡ç­¾çš„EEGæ•°æ®é›†ã€‚è¯¥ç ”ç©¶æ¶‰åŠ30åå‚ä¸è€…ï¼Œæ”¶é›†äº†3,657æ¬¡äº’åŠ¨ï¼Œæä¾›äº†ä¸€ä¸ªä¸°å¯Œçš„æ•°æ®é›†ï¼Œå¯ç”¨äºæ›´æ·±å…¥åœ°æ¢ç´¢ç”¨æˆ·åå¥½å’Œè®¤çŸ¥æ´»åŠ¨ã€‚é€šè¿‡ç»“åˆè‡ªæˆ‘è¯„ä¼°æŠ€æœ¯å’Œå®æ—¶ã€ä½æˆæœ¬çš„EEGä¿¡å·ï¼Œæˆ‘ä»¬æä¾›äº†å¯¹ç”¨æˆ·æƒ…æ„Ÿä½“éªŒï¼ˆæƒ…ç»ªã€å”¤é†’åº¦ã€æ²‰æµ¸æ„Ÿã€å…´è¶£ã€è§†è§‰å’Œå¬è§‰ï¼‰ä»¥åŠå…¶è¡Œä¸ºèƒŒåçš„è®¤çŸ¥æœºåˆ¶æ›´è¯¦ç»†çš„ç†è§£ã€‚æˆ‘ä»¬é€šè¿‡æ¨èç®—æ³•çš„è¯„åˆ†é¢„æµ‹å»ºç«‹äº†åŸºå‡†ï¼Œå¹¶å±•ç¤ºäº†åŠ å…¥EEGä¿¡å·åçš„æ˜¾è‘—æ”¹è¿›ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬å±•ç¤ºäº†è¯¥æ•°æ®é›†åœ¨æ´å¯Ÿæ¨èç³»ç»Ÿä¸­ç”¨æˆ·è¡Œä¸ºèƒŒåçš„æƒ…æ„Ÿä½“éªŒå’Œè®¤çŸ¥æ´»åŠ¨æ–¹é¢çš„æ½œåŠ›ã€‚è¿™é¡¹å·¥ä½œé€šè¿‡åˆ©ç”¨EEGä¿¡å·å’Œå¤šç»´æƒ…æ„Ÿå‚ä¸åˆ†æ•°ä¸­è•´å«çš„ä¸°å¯Œä¿¡æ¯ï¼Œæå‡ºäº†ä¸€ä¸ªå¢å¼ºçŸ­è§†é¢‘æ¨èçš„æ–°è§†è§’ï¼Œä¸ºæœªæ¥çŸ­è§†é¢‘æ¨èç³»ç»Ÿçš„ç ”ç©¶é“ºå¹³äº†é“è·¯ã€‚  
**âœ…Cross-channel Recommendation for Multi-channel Retail**  
An increasing number of brick-and-mortar retailers are expanding their channels to the online domain, transforming them into multi-channel retailers. This transition emphasizes the need for cross-channel recommender systems, aiming to enhance revenue across both offline and online channels. Given that each retail channel represents a separate domain with a unique context, this can be regarded as a cross-domain recommendation (CDR). However, the existing studies on CDR did not address the scenarios where both users and items partially overlap across multi-retail channels which we define as "cross-channel retail recommendation (CCRR)". This paper introduces our original work on CCRR using real-world datasets from a multi-channel retail store. Specifically, (1) we present significant challenges in integrating user preferences across both channels. (2) Accordingly, we propose a novel model for CCRR using a channel-wise attention mechanism to capture different user preferences for the same item on each channel. We empirically validate our model's superiority in addressing CCRR over existing models. (3) Finally, we offer implications for future research on CCRR, delving into our experiment results.  
éšç€è¶Šæ¥è¶Šå¤šçš„å®ä½“é›¶å”®å•†å°†ä¸šåŠ¡æ‹“å±•è‡³åœ¨çº¿é¢†åŸŸï¼Œå°†å®ƒä»¬è½¬å˜ä¸ºå¤šæ¸ é“é›¶å”®å•†ã€‚è¿™ç§è½¬å˜å¼ºè°ƒäº†è·¨æ¸ é“æ¨èç³»ç»Ÿçš„éœ€æ±‚ï¼Œæ—¨åœ¨å¢å¼ºçº¿ä¸‹å’Œçº¿ä¸Šæ¸ é“çš„æ”¶å…¥ã€‚ç”±äºæ¯ä¸ªé›¶å”®æ¸ é“ä»£è¡¨ç€ä¸€ä¸ªå…·æœ‰ç‹¬ç‰¹èƒŒæ™¯çš„ç‹¬ç«‹é¢†åŸŸï¼Œè¿™å¯ä»¥è¢«è§†ä¸ºè·¨é¢†åŸŸæ¨èï¼ˆCDRï¼‰ã€‚ç„¶è€Œï¼Œç°æœ‰çš„CDRç ”ç©¶å¹¶æ²¡æœ‰æ¶‰åŠåˆ°ç”¨æˆ·å’Œç‰©å“åœ¨å¤šä¸ªé›¶å”®æ¸ é“ä¸Šéƒ¨åˆ†é‡å çš„æƒ…å†µï¼Œæˆ‘ä»¬å®šä¹‰è¿™ç§æƒ…å†µä¸ºâ€œè·¨æ¸ é“é›¶å”®æ¨èï¼ˆCCRRï¼‰â€ã€‚æœ¬æ–‡ä»‹ç»äº†æˆ‘ä»¬åœ¨CCRRä¸Šçš„åŸåˆ›å·¥ä½œï¼Œä½¿ç”¨äº†æ¥è‡ªå¤šæ¸ é“é›¶å”®å•†çš„çœŸå®æ•°æ®é›†ã€‚å…·ä½“æ¥è¯´ï¼Œï¼ˆ1ï¼‰æˆ‘ä»¬æå‡ºäº†åœ¨æ•´åˆè·¨æ¸ é“ç”¨æˆ·åå¥½æ—¶é¢ä¸´çš„é‡å¤§æŒ‘æˆ˜ã€‚ï¼ˆ2ï¼‰å› æ­¤ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°é¢–çš„CCRRæ¨¡å‹ï¼Œä½¿ç”¨äº†æ¸ é“çº§åˆ«çš„æ³¨æ„åŠ›æœºåˆ¶æ¥æ•æ‰åœ¨æ¯ä¸ªæ¸ é“ä¸Šå¯¹åŒä¸€ç‰©å“çš„ä¸åŒç”¨æˆ·åå¥½ã€‚æˆ‘ä»¬é€šè¿‡å®éªŒè¯å®äº†æˆ‘ä»¬æ¨¡å‹åœ¨å¤„ç†CCRRæ–¹é¢ä¼˜äºç°æœ‰æ¨¡å‹çš„ä¼˜è¶Šæ€§ã€‚ï¼ˆ3ï¼‰æœ€åï¼Œæˆ‘ä»¬æä¾›äº†å¯¹æœªæ¥CCRRç ”ç©¶çš„å¯ç¤ºï¼Œæ·±å…¥åˆ†æäº†æˆ‘ä»¬çš„å®éªŒç»“æœã€‚
**âœ…Maximizing User Experience with LLMOps-Driven Personalized Recommendation Systems**  
The integration of LLMOps into personalized recommendation systems marks a significant advancement in managing LLM-driven applications. This innovation presents both opportunities and challenges for enterprises, requiring specialized teams to navigate the complexity of engineering technology while prioritizing data security and model interpretability. By leveraging LLMOps, enterprises can enhance the efficiency and reliability of large-scale machine learning models, driving personalized recommendations aligned with user preferences. Despite ethical considerations, LLMOps is poised for widespread adoption, promising more efficient and secure machine learning services that elevate user experience and shape the future of personalized recommendation systems.    
å°†LLMOpsæ•´åˆåˆ°ä¸ªæ€§åŒ–æ¨èç³»ç»Ÿä¸­æ ‡å¿—ç€åœ¨ç®¡ç†LLMé©±åŠ¨åº”ç”¨æ–¹é¢çš„é‡å¤§è¿›å±•ã€‚è¿™ç§åˆ›æ–°ä¸ºä¼ä¸šæä¾›äº†æœºé‡å’ŒæŒ‘æˆ˜ï¼Œéœ€è¦ä¸“ä¸šå›¢é˜Ÿåœ¨å¤„ç†å·¥ç¨‹æŠ€æœ¯å¤æ‚æ€§çš„åŒæ—¶ï¼Œä¼˜å…ˆè€ƒè™‘æ•°æ®å®‰å…¨æ€§å’Œæ¨¡å‹å¯è§£é‡Šæ€§ã€‚é€šè¿‡åˆ©ç”¨LLMOpsï¼Œä¼ä¸šå¯ä»¥æé«˜å¤§è§„æ¨¡æœºå™¨å­¦ä¹ æ¨¡å‹çš„æ•ˆç‡å’Œå¯é æ€§ï¼Œæ¨åŠ¨ä¸ç”¨æˆ·åå¥½ä¸€è‡´çš„ä¸ªæ€§åŒ–æ¨èã€‚å°½ç®¡å­˜åœ¨ä¼¦ç†è€ƒè™‘ï¼ŒLLMOpså·²ç»å‡†å¤‡å¥½è¢«å¹¿æ³›é‡‡ç”¨ï¼Œæ‰¿è¯ºæä¾›æ›´é«˜æ•ˆã€æ›´å®‰å…¨çš„æœºå™¨å­¦ä¹ æœåŠ¡ï¼Œæå‡ç”¨æˆ·ä½“éªŒï¼Œå¡‘é€ ä¸ªæ€§åŒ–æ¨èç³»ç»Ÿçš„æœªæ¥ã€‚




  
